{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import Necessary Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "from operator import itemgetter\n",
    "from helpers import get_llm, get_retriever\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.prompts import ChatPromptTemplate, PromptTemplate\n",
    "from langchain_core.messages import HumanMessage\n",
    "from langchain_core.runnables import Runnable, RunnablePassthrough, RunnableParallel, RunnableLambda, chain\n",
    "from langchain_core.tools import tool\n",
    "from typing import Annotated\n",
    "import requests\n",
    "from langchain.callbacks.tracers import ConsoleCallbackHandler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Configure Database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "from helpers.config import Config\n",
    "from sqlalchemy import create_engine\n",
    "\n",
    "sql_engine = create_engine(f\"{Config.POSTGRES_CONNECTION_STRING}/sql_agent\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ingest Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inserted data from sheet 'brillar_bank' into table 'brillar_bank'\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from helpers import get_vector_store_instance\n",
    "from langchain_core.documents import Document\n",
    "\n",
    "df = pd.read_excel(\"./sample_data/brillar_bank_fixed_deposit.xlsx\", sheet_name=None)\n",
    "\n",
    "\n",
    "vector_store = get_vector_store_instance(embedding_model=\"text-embedding-3-large\", dimension=256, index_name=\"test\", vector_db=\"qdrant\")\n",
    "vector_store.add_documents(\n",
    "    [\n",
    "        Document(\n",
    "            page_content=\"This data includes Brillar Bank's fixed deposit accounts and the customer information. This includes customer name, fixed deposit type, amount in RM, term of deposit in months, customer id, customer age, customer location, and customer phone number.\",\n",
    "            metadata={\"search_type\": \"xlsx\", \"source\": \"brillar_bank_fixed_deposit.xlsx\"},\n",
    "        )\n",
    "    ]\n",
    ")\n",
    "for sheet_name, df in df.items():\n",
    "    table_name = sheet_name.replace(\" \", \"_\").lower()\n",
    "    df.to_sql(name=table_name, con=sql_engine, if_exists=\"replace\", index=False)\n",
    "    print(f\"Inserted data from sheet '{sheet_name}' into table '{table_name}'\")\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initiate LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = get_llm(\"gpt-4o\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.tools import tool\n",
    "from langchain_community.utilities import SQLDatabase\n",
    "from langchain.chains.sql_database.query import create_sql_query_chain\n",
    "from langchain_community.tools.sql_database.tool import QuerySQLDataBaseTool\n",
    "from langgraph.graph import END, START, StateGraph, MessagesState\n",
    "\n",
    "def classification(state: MessagesState):\n",
    "  classification_prompt = \"\"\"Analyze the question and decide that if the question can be answered from a structured data or unstructured data. You should only response STRUCTURED or UNSTRUCTURED.\n",
    "\n",
    "        Structured data schema:\n",
    "        [Customer Name, Fixed Deposit Type, Amount (RM), Term (Months), Customer Age, Customer Location, Customer Phone Number]\n",
    "        \n",
    "        Question: {question}\n",
    "        Output: \"\"\"\n",
    "  \n",
    "  classification_template = ChatPromptTemplate.from_template(classification_prompt)\n",
    "  classification_chain = classification_template | llm | StrOutputParser()\n",
    "  response = classification_chain.invoke(state[\"messages\"])\n",
    "\n",
    "  if response == \"STRUCTURED\":\n",
    "    return \"sql\"\n",
    "  else:\n",
    "    return \"rag\"\n",
    "\n",
    "\n",
    "def rag_chain(state: MessagesState):\n",
    "  messages = state[\"messages\"]\n",
    "  qa_instructions = (\n",
    "        \"\"\"Answer the user question given the following context:\\n\\n{context}.\"\"\"\n",
    "    )\n",
    "  qa_prompt = ChatPromptTemplate.from_messages(\n",
    "        [(\"system\", qa_instructions), (\"human\", \"{question}\")]\n",
    "    )\n",
    "  \n",
    "  retriever = get_retriever(\n",
    "        index_name=\"test\",\n",
    "        embedding_model=\"text-embedding-3-large\",\n",
    "        dimension=256,\n",
    "        vector_db=\"qdrant\",\n",
    "        top_k=5,\n",
    "    )\n",
    "  \n",
    "  chain = {\n",
    "                \"question\": itemgetter(\"question\"),\n",
    "                \"context\": itemgetter(\"question\") | retriever,\n",
    "            } | qa_prompt | llm | StrOutputParser()\n",
    "  \n",
    "  response = chain.invoke({\"question\": messages[-1].content})\n",
    "  return {\"messages\": [response]}\n",
    "\n",
    "\n",
    "def sql_chain(state: MessagesState):\n",
    "  messages = state[\"messages\"]\n",
    "  sql_instruction = \"\"\"\n",
    "        You are a PostgreSQL expert. Given an input question, first create a syntactically correct PostgreSQL query, and then ONLY return the plain query. No markdown format or explanation is needed.\n",
    "        Unless the user specifies in the question a specific number of examples to obtain, query for at most {top_k} results using the LIMIT clause as per PostgreSQL. You can order the results to return the most informative data in the database.\n",
    "        Never query for all columns from a table. You must query only the columns that are needed to answer the question. Wrap each column name in double quotes (\") to denote them as delimited identifiers.\n",
    "        Pay attention to use only the column names you can see in the tables below. Be careful to not query for columns that do not exist. Also, pay attention to which column is in which table.\n",
    "        Pay attention to use CURRENT_DATE function to get the current date, if the question involves \"today\".\n",
    "\n",
    "        Only use the following tables:\n",
    "        {table_info}\n",
    "\n",
    "        Question: {input}\n",
    "        \"\"\"\n",
    "  \n",
    "  sql_prompt = PromptTemplate.from_template(template=sql_instruction)\n",
    "\n",
    "  db = SQLDatabase(engine=sql_engine)\n",
    "\n",
    "  write_query = create_sql_query_chain(llm, db, prompt=sql_prompt)\n",
    "  execute_query = QuerySQLDataBaseTool(db=db)\n",
    "  sql_prompt = PromptTemplate.from_template(\n",
    "      \"\"\"Given the following user question, corresponding SQL query, and SQL result, answer the user question. You don't need to tell the user that you are using SQL.\n",
    "\n",
    "  Question: {question}\n",
    "  SQL Query: {query}\n",
    "  SQL Result: {result}\n",
    "  Answer: \"\"\"\n",
    "  )\n",
    "\n",
    "  sql_chain = RunnablePassthrough.assign(query=write_query).assign(result=itemgetter(\"query\") | execute_query) | sql_prompt | llm | StrOutputParser()\n",
    "\n",
    "  response = sql_chain.invoke({\"question\": messages[-1].content})\n",
    "  return {\"messages\": [response]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "workflow = StateGraph(MessagesState)\n",
    "workflow.add_node(\"rag\", rag_chain)\n",
    "workflow.add_node(\"sql\", sql_chain)\n",
    "\n",
    "workflow.add_conditional_edges(START, classification)\n",
    "workflow.add_edge(\"rag\", END)\n",
    "workflow.add_edge(\"sql\", END)\n",
    "\n",
    "app = workflow.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'messages': [HumanMessage(content='How many types of fixed deposit do you offer?', id='828b738d-51b1-4a33-b7fc-cc533d644097'),\n",
       "  HumanMessage(content='We offer 6 types of fixed deposit.', id='f811991b-5be3-412f-b5ef-7ce7c9b3c8e8')]}"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "app.invoke({\"messages\": [HumanMessage(content=\"How many types of fixed deposit do you offer?\")]})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "virtualenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
